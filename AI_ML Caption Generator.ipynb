{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0ee15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\anaconda\\anaconda\\lib\\site-packages (4.29.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in e:\\anaconda\\anaconda\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\anaconda\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: fsspec in e:\\anaconda\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\anaconda\\anaconda\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: torch in e:\\anaconda\\anaconda\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\anaconda\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: sympy in e:\\anaconda\\anaconda\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\anaconda\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\anaconda\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\anaconda\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in e:\\anaconda\\anaconda\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\anaconda\\anaconda\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: pillow in e:\\anaconda\\anaconda\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: torchvision in e:\\anaconda\\anaconda\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\anaconda\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\anaconda\\anaconda\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: torch==2.0.1 in e:\\anaconda\\anaconda\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\anaconda\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: sympy in e:\\anaconda\\anaconda\\lib\\site-packages (from torch==2.0.1->torchvision) (1.10.1)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\anaconda\\lib\\site-packages (from torch==2.0.1->torchvision) (3.6.0)\n",
      "Requirement already satisfied: networkx in e:\\anaconda\\anaconda\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\anaconda\\lib\\site-packages (from torch==2.0.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\anaconda\\lib\\site-packages (from torch==2.0.1->torchvision) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\anaconda\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in e:\\anaconda\\anaconda\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\anaconda\\anaconda\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install pillow\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e6c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Transformers library for vision encoder-decoder model\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "\n",
    "# PyTorch for deep learning framework\n",
    "import torch\n",
    "\n",
    "# PIL (Python Imaging Library) for image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Flask for creating web application\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "# OS module for file operations\n",
    "import os\n",
    "\n",
    "# TorchVision for image transformations\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770ca15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [30/May/2023 14:08:03] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2023 14:08:22] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/May/2023 14:08:22] \"GET /Ass1/Image1.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__, template_folder='C:/Users/Computer/Desktop/Ass1', static_folder='C:/Users/Computer/Desktop/Ass1')\n",
    "\n",
    "# Load pre-trained vision encoder-decoder model\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# Load pre-trained ViT (Vision Transformer) feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# Load pre-trained tokenizer for caption generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set parameters for caption generation\n",
    "max_length = 16  # Maximum length of the beam\n",
    "total_beams = 5  # Maximum number of beams to consider while generating captions\n",
    "generate_parameters = {\"max_length\": max_length, \"num_beams\": total_beams}\n",
    "\n",
    "# Function to generate captions for an image\n",
    "def generate_captions(image_path, num_captions):\n",
    "    try:\n",
    "        # Open and preprocess the image\n",
    "        image = Image.open(image_path)\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(mode=\"RGB\")\n",
    "        images = [image]\n",
    "        # Extract image features using the ViT feature extractor\n",
    "        image_features = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "        image_features = image_features.to(device)\n",
    "        # Generate captions using the vision encoder-decoder model\n",
    "        output_captions = model.generate(image_features, **generate_parameters, num_return_sequences=num_captions)\n",
    "        # Decode and post-process the generated captions\n",
    "        generated_captions = tokenizer.batch_decode(output_captions, skip_special_tokens=True)\n",
    "        generated_captions = [caption.strip() for caption in generated_captions]\n",
    "        return generated_captions\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating captions: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Define a Flask route for uploading an image and generating captions\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def upload_and_generate_caption():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            # Retrieve the uploaded image file and the number of captions to generate\n",
    "            image_file = request.files['file']\n",
    "            num_captions = int(request.form['num_captions'])\n",
    "            if image_file:\n",
    "                # Define the folder to save the uploaded image\n",
    "                app.config['UPLOAD_FOLDER'] = 'C:/Users/Computer/Desktop/Ass1'\n",
    "                image_path = os.path.join(app.config['UPLOAD_FOLDER'], image_file.filename)\n",
    "                # Save the uploaded image to the specified folder\n",
    "                image_file.save(image_path)\n",
    "                # Generate captions for the uploaded image\n",
    "                captions = generate_captions(image_path, num_captions)\n",
    "                # Render the result template with the uploaded image filename and generated captions\n",
    "                return render_template(\"result.html\", filename=image_file.filename, captions=captions)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing the image: {str(e)}\")\n",
    "    # Render the index template for uploading the image\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004cbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
